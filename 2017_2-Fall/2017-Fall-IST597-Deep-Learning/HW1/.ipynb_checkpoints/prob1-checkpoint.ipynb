{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os  \n",
    "import numpy as np  \n",
    "import pandas as pd  \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def computeCost(X, y, theta):\n",
    "    # loss is now Bernoulli cross-entropy/log likelihood\n",
    "    w = theta[0]\n",
    "    b = theta[1]\n",
    "    return (sum([(w[0]*X[i,0]+b[0]-y[i,0])**2 for i in list(range(0,X.shape[0]))])/(2*X.shape[0]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def computeGrad(X, y, theta): \n",
    "\t# WRITEME: write your code here to complete the routine\n",
    "\t# NOTE: you do not have to use the partial derivative symbols below, they are there to guide your thinking\n",
    "    b = theta[0]\n",
    "    w = theta[1]\n",
    "    m = X.shape[0]\n",
    "    dL_db = (1/m)*sum([(w[0]*X[i,0]+b[0]-y[i,0]) for i in list(range(0,X.shape[0]))])[0,0] # derivative w.r.t. model weights w\n",
    "    dL_dw = (1/m)*sum([(w[0]*X[i,0]+b[0]-y[i,0])*X[i,0] for i in list(range(0,X.shape[0]))])[0,0] # derivative w.r.t model bias b\n",
    "    nabla = (dL_db, dL_dw) # nabla represents the full gradient\n",
    "    return nabla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NOTE: you will need to tinker with the meta-parameters below yourself (do not think of them as defaults by any means)\n",
    "# meta-parameters for program\n",
    "alpha = 0.1 # step size coefficient\n",
    "eps = 0.001 # controls convergence criterion\n",
    "n_epoch = 50 # number of epochs (full passes through the dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = os.getcwd() + '/data/prob1.dat'  \n",
    "data = pd.read_csv(path, header=None, names=['X', 'Y']) \n",
    "\n",
    "# display some information about the dataset itself here\n",
    "# WRITEME: write your code here to print out information/statistics about the data-set \"data\" using Pandas (consult the Pandas documentation to learn how)\n",
    "# WRITEME: write your code here to create a simple scatterplot of the dataset itself and print/save to disk the result\n",
    "\n",
    "# set X (training data) and y (target variable)\n",
    "cols = data.shape[1]  \n",
    "X = data.iloc[:,0:cols-1]  \n",
    "y = data.iloc[:,cols-1:cols] \n",
    "\n",
    "# convert from data frames to numpy matrices\n",
    "X = np.array(X.values)  \n",
    "y = np.array(y.values)\n",
    "\n",
    "# convert to numpy arrays and initalize the parameter array theta \n",
    "w = np.zeros((1,X.shape[1]))\n",
    "b = np.array([0])\n",
    "theta = (b, w)\n",
    "\n",
    "L = computeCost(X, y, theta)\n",
    "print(\"-1 L = {0}\".format(L))\n",
    "L_best = L\n",
    "i = 0\n",
    "cost = [] # you can use this list variable to help you create the loss versus epoch plot at the end (if you want)\n",
    "while(i < n_epoch):\n",
    "    dL_db, dL_dw = computeGrad(X, y, theta)\n",
    "    b = theta[0]\n",
    "    w = theta[1]\n",
    "    \n",
    "    # update rules go here...\n",
    "    # WRITEME: write your code here to perform a step of gradient descent & record anything else desired for later\n",
    "    b = b - alpha*dL_db\n",
    "    w = w - alpha*dL_dw\n",
    "    # (note: don't forget to override the theta variable...)\n",
    "    theta = (b, w)\n",
    "    \n",
    "    L = computeCost(X, y, theta) # track our loss after performing a single step\n",
    "    \n",
    "    print(\" {0} L = {1}\".format(i,L))\n",
    "    i += 1\n",
    "# print parameter values found after the search\n",
    "print(\"w = \",w)\n",
    "print(\"b = \",b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 17.592  ],\n",
       "       [  9.1302 ],\n",
       "       [ 13.662  ],\n",
       "       [ 11.854  ],\n",
       "       [  6.8233 ],\n",
       "       [ 11.886  ],\n",
       "       [  4.3483 ],\n",
       "       [ 12.     ],\n",
       "       [  6.5987 ],\n",
       "       [  3.8166 ],\n",
       "       [  3.2522 ],\n",
       "       [ 15.505  ],\n",
       "       [  3.1551 ],\n",
       "       [  7.2258 ],\n",
       "       [  0.71618],\n",
       "       [  3.5129 ],\n",
       "       [  5.3048 ],\n",
       "       [  0.56077],\n",
       "       [  3.6518 ],\n",
       "       [  5.3893 ],\n",
       "       [  3.1386 ],\n",
       "       [ 21.767  ],\n",
       "       [  4.263  ],\n",
       "       [  5.1875 ],\n",
       "       [  3.0825 ],\n",
       "       [ 22.638  ],\n",
       "       [ 13.501  ],\n",
       "       [  7.0467 ],\n",
       "       [ 14.692  ],\n",
       "       [ 24.147  ],\n",
       "       [ -1.22   ],\n",
       "       [  5.9966 ],\n",
       "       [ 12.134  ],\n",
       "       [  1.8495 ],\n",
       "       [  6.5426 ],\n",
       "       [  4.5623 ],\n",
       "       [  4.1164 ],\n",
       "       [  3.3928 ],\n",
       "       [ 10.117  ],\n",
       "       [  5.4974 ],\n",
       "       [  0.55657],\n",
       "       [  3.9115 ],\n",
       "       [  5.3854 ],\n",
       "       [  2.4406 ],\n",
       "       [  6.7318 ],\n",
       "       [  1.0463 ],\n",
       "       [  5.1337 ],\n",
       "       [  1.844  ],\n",
       "       [  8.0043 ],\n",
       "       [  1.0179 ],\n",
       "       [  6.7504 ],\n",
       "       [  1.8396 ],\n",
       "       [  4.2885 ],\n",
       "       [  4.9981 ],\n",
       "       [  1.4233 ],\n",
       "       [ -1.4211 ],\n",
       "       [  2.4756 ],\n",
       "       [  4.6042 ],\n",
       "       [  3.9624 ],\n",
       "       [  5.4141 ],\n",
       "       [  5.1694 ],\n",
       "       [ -0.74279],\n",
       "       [ 17.929  ],\n",
       "       [ 12.054  ],\n",
       "       [ 17.054  ],\n",
       "       [  4.8852 ],\n",
       "       [  5.7442 ],\n",
       "       [  7.7754 ],\n",
       "       [  1.0173 ],\n",
       "       [ 20.992  ],\n",
       "       [  6.6799 ],\n",
       "       [  4.0259 ],\n",
       "       [  1.2784 ],\n",
       "       [  3.3411 ],\n",
       "       [ -2.6807 ],\n",
       "       [  0.29678],\n",
       "       [  3.8845 ],\n",
       "       [  5.7014 ],\n",
       "       [  6.7526 ],\n",
       "       [  2.0576 ],\n",
       "       [  0.47953],\n",
       "       [  0.20421],\n",
       "       [  0.67861],\n",
       "       [  7.5435 ],\n",
       "       [  5.3436 ],\n",
       "       [  4.2415 ],\n",
       "       [  6.7981 ],\n",
       "       [  0.92695],\n",
       "       [  0.152  ],\n",
       "       [  2.8214 ],\n",
       "       [  1.8451 ],\n",
       "       [  4.2959 ],\n",
       "       [  7.2029 ],\n",
       "       [  1.9869 ],\n",
       "       [  0.14454],\n",
       "       [  9.0551 ],\n",
       "       [  0.61705]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.058621413657757"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = theta[0]\n",
    "b = theta[1]\n",
    "sum([(w[0]*X[i,0]+b[0]-y[i,0])**2 for i in list(range(0,X.shape[0]))])/(2*X.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[16, 25, 36, 49, 64, 81]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i**2 for i in list(range(4,10))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.08985749],\n",
       "       [ 0.50967393]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     17.59200\n",
       "1      9.13020\n",
       "2     13.66200\n",
       "3     11.85400\n",
       "4      6.82330\n",
       "5     11.88600\n",
       "6      4.34830\n",
       "7     12.00000\n",
       "8      6.59870\n",
       "9      3.81660\n",
       "10     3.25220\n",
       "11    15.50500\n",
       "12     3.15510\n",
       "13     7.22580\n",
       "14     0.71618\n",
       "15     3.51290\n",
       "16     5.30480\n",
       "17     0.56077\n",
       "18     3.65180\n",
       "19     5.38930\n",
       "20     3.13860\n",
       "21    21.76700\n",
       "22     4.26300\n",
       "23     5.18750\n",
       "24     3.08250\n",
       "25    22.63800\n",
       "26    13.50100\n",
       "27     7.04670\n",
       "28    14.69200\n",
       "29    24.14700\n",
       "        ...   \n",
       "67     7.77540\n",
       "68     1.01730\n",
       "69    20.99200\n",
       "70     6.67990\n",
       "71     4.02590\n",
       "72     1.27840\n",
       "73     3.34110\n",
       "74    -2.68070\n",
       "75     0.29678\n",
       "76     3.88450\n",
       "77     5.70140\n",
       "78     6.75260\n",
       "79     2.05760\n",
       "80     0.47953\n",
       "81     0.20421\n",
       "82     0.67861\n",
       "83     7.54350\n",
       "84     5.34360\n",
       "85     4.24150\n",
       "86     6.79810\n",
       "87     0.92695\n",
       "88     0.15200\n",
       "89     2.82140\n",
       "90     1.84510\n",
       "91     4.29590\n",
       "92     7.20290\n",
       "93     1.98690\n",
       "94     0.14454\n",
       "95     9.05510\n",
       "96     0.61705\n",
       "Name: Y, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def computeCost(X, y, theta): # loss is now Bernoulli cross-entropy/log likelihood\n",
    "\t# WRITEME: write your code here to complete the routine\n",
    "\treturn -1.0\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
